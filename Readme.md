# Kaggle - Toxic Comments Classification Challenge
<hr>

https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/overview/description

<hr>

This repository contains a very quick model built to solve the Kaggle Toxic Comments Classification Challenge. A lot of time has not been spent on training the model to a great accuracy.<br>
*The objcetive here was to learn how to build multi-label language classification models using Fast.ai's ULMFIT (Universal Lnaguage Model Fitting) approach.*

With a few hours of training, I was able to get an accuracy of `99.26%` and an `ROC-AUC` score of `99.7%` on `10%` of the training data kept aside for validation.

Requirements :
- Fastai V1
- PyTorch
- Dependencies of the above two libraries.